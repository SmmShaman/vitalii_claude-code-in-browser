import { serve } from 'https://deno.land/std@0.168.0/http/server.ts'
import { createClient } from 'https://esm.sh/@supabase/supabase-js@2.39.0'
import { getRandomStylePrompt } from './style-prompts.ts'

const corsHeaders = {
  'Access-Control-Allow-Origin': '*',
  'Access-Control-Allow-Headers': 'authorization, x-client-info, apikey, content-type',
}

const SUPABASE_URL = Deno.env.get('SUPABASE_URL')!
const SUPABASE_SERVICE_ROLE_KEY = Deno.env.get('SUPABASE_SERVICE_ROLE_KEY')!
const AZURE_OPENAI_ENDPOINT = Deno.env.get('AZURE_OPENAI_ENDPOINT')
const AZURE_OPENAI_API_KEY = Deno.env.get('AZURE_OPENAI_API_KEY')

// Version for deployment verification
const VERSION = '2026-02-08-v11-surreal-style-first'

interface PromptVariant {
  label: string
  description: string
  stylePrompt?: string  // Random style used for this variant set
}

interface GeneratePromptRequest {
  newsId: string
  title: string
  content: string
  mode?: 'variants' | 'full'
  selectedVariant?: PromptVariant
}

interface GeneratePromptResponse {
  success: boolean
  prompt?: string
  variants?: PromptVariant[]
  classifierData?: ClassifierOutput
  templateUsed?: string
  approach?: string
  error?: string
}

// Pre-Analyzer output - decides which approach to use
interface PreAnalyzerOutput {
  approach: 'structured' | 'creative' | 'hero_image' | 'artistic'
  mood: string
  complexity: 'simple' | 'medium' | 'complex'
  reason: string
  suggested_style: string
  color_mood: string
  key_emotion: string
  core_idea: string
  visual_metaphor: string
}

// Structured output from classifier (for structured approach)
interface ClassifierOutput {
  company_name: string
  company_domain: string
  category: 'tech_product' | 'marketing_campaign' | 'ai_research' | 'business_news' | 'science' | 'lifestyle' | 'general'
  product_type: string
  key_features: string[]
  visual_elements: string[]
  visual_concept: string
  color_scheme: string
  style_hint: string
}

// Map category to template prompt_type
const CATEGORY_TO_TEMPLATE: Record<string, string> = {
  'tech_product': 'image_template_tech_product',
  'marketing_campaign': 'image_template_marketing_campaign',
  'ai_research': 'image_template_ai_research',
  'business_news': 'image_template_business_news',
  'science': 'image_template_science',
  'lifestyle': 'image_template_lifestyle',
  'general': 'image_template_general',
}

// Default colors for categories
const CATEGORY_COLORS: Record<string, { primary: string; secondary: string }> = {
  'tech_product': { primary: '#00E5FF', secondary: '#FF2D92' },
  'marketing_campaign': { primary: '#FF6B35', secondary: '#004E89' },
  'ai_research': { primary: '#7C3AED', secondary: '#00E5FF' },
  'business_news': { primary: '#0066CC', secondary: '#00AA55' },
  'science': { primary: '#10B981', secondary: '#3B82F6' },
  'lifestyle': { primary: '#F59E0B', secondary: '#EC4899' },
  'general': { primary: '#6366F1', secondary: '#8B5CF6' },
}

/**
 * Generate professional image prompt using ADAPTIVE two-level process:
 *
 * LEVEL 1: Pre-Analyzer decides WHICH approach to use
 * LEVEL 2: Either use structured templates OR generate creative unique prompt
 *
 * This provides variety - not all images will be infographics!
 */
serve(async (req) => {
  console.log(`ğŸ¨ Generate Image Prompt ${VERSION} started`)

  if (req.method === 'OPTIONS') {
    return new Response('ok', { headers: corsHeaders })
  }

  try {
    const requestData: GeneratePromptRequest = await req.json()
    const mode = requestData.mode || 'full'
    console.log(`ğŸ“ Processing article (mode=${mode}):`, requestData.title?.substring(0, 50) + '...')

    if (!requestData.newsId || !requestData.title || !requestData.content) {
      throw new Error('Missing required fields: newsId, title, content')
    }

    if (!AZURE_OPENAI_ENDPOINT || !AZURE_OPENAI_API_KEY) {
      throw new Error('Azure OpenAI not configured')
    }

    const supabase = createClient(SUPABASE_URL, SUPABASE_SERVICE_ROLE_KEY)

    // â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    // MODE: VARIANTS - Generate 4 visual concept options
    // â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    if (mode === 'variants') {
      console.log('ğŸ¨ Generating 4 visual concept variants...')
      const variants = await generateVariants(supabase, requestData.title, requestData.content)

      if (!variants || variants.length === 0) {
        throw new Error('Failed to generate visual concept variants')
      }

      // Save variants to database
      const { error: updateError } = await supabase
        .from('news')
        .update({
          image_prompt_variants: variants,
        })
        .eq('id', requestData.newsId)

      if (updateError) {
        console.error('Failed to save variants to database:', updateError)
        throw new Error('Failed to save variants')
      }

      console.log(`âœ… ${variants.length} variants generated and saved`)

      return new Response(
        JSON.stringify({
          success: true,
          variants,
        } as GeneratePromptResponse),
        { headers: { ...corsHeaders, 'Content-Type': 'application/json' } }
      )
    }

    // â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    // MODE: FULL - Generate complete image prompt (original flow)
    // â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

    // â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    // LEVEL 1: Pre-Analyzer - Decide which approach to use
    // â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    console.log('ğŸ”® Level 1: Running Pre-Analyzer to decide approach...')
    const preAnalysis = await runPreAnalyzer(supabase, requestData.title, requestData.content, requestData.selectedVariant)

    if (!preAnalysis) {
      console.warn('âš ï¸ Pre-Analyzer failed, defaulting to structured approach')
    }

    const approach = preAnalysis?.approach || 'structured'
    console.log(`âœ… Pre-Analyzer decision: ${approach} (${preAnalysis?.reason || 'default'})`)

    let finalPrompt: string
    let classifierData: ClassifierOutput | null = null
    let templateUsed: string | null = null

    // â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    // LEVEL 2: Execute chosen approach
    // â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    if (approach === 'structured') {
      // STRUCTURED APPROACH: Use classifier + templates (for complex/data-heavy news)
      console.log('ğŸ“Š Level 2: Using STRUCTURED approach (classifier + template)')

      classifierData = await runClassifier(supabase, requestData.title, requestData.content)
      if (!classifierData) {
        throw new Error('Classifier failed to extract data')
      }

      templateUsed = CATEGORY_TO_TEMPLATE[classifierData.category] || 'image_template_general'
      const template = await getTemplate(supabase, templateUsed)
      finalPrompt = fillTemplate(template || getDefaultTemplate(), classifierData)

    } else {
      // CREATIVE APPROACH: Generate unique prompt (for simple/emotional news)
      console.log(`ğŸ¨ Level 2: Using CREATIVE approach (${approach})`)

      finalPrompt = await generateCreativePrompt(
        supabase,
        requestData.title,
        requestData.content,
        preAnalysis!,
        requestData.selectedVariant
      )

      if (!finalPrompt) {
        // Fallback to structured if creative fails
        console.warn('âš ï¸ Creative prompt generation failed, falling back to structured')
        classifierData = await runClassifier(supabase, requestData.title, requestData.content)
        if (classifierData) {
          templateUsed = CATEGORY_TO_TEMPLATE[classifierData.category] || 'image_template_general'
          const template = await getTemplate(supabase, templateUsed)
          finalPrompt = fillTemplate(template || getDefaultTemplate(), classifierData)
        } else {
          throw new Error('Both creative and structured approaches failed')
        }
      }
    }

    console.log('âœ… Final prompt generated:', finalPrompt.substring(0, 200) + '...')

    // Save to database with approach metadata
    const { error: updateError } = await supabase
      .from('news')
      .update({
        image_generation_prompt: finalPrompt,
        prompt_generated_at: new Date().toISOString(),
      })
      .eq('id', requestData.newsId)

    if (updateError) {
      console.error('Failed to save prompt to database:', updateError)
      throw new Error('Failed to save prompt')
    }

    // Increment usage count
    const promptTypeUsed = approach === 'structured' ? 'image_classifier' : 'image_creative_writer'
    try {
      await supabase.rpc('increment_prompt_usage', { prompt_type_param: promptTypeUsed })
    } catch (e) {
      // Ignore RPC errors
    }

    return new Response(
      JSON.stringify({
        success: true,
        prompt: finalPrompt,
        classifierData,
        templateUsed,
        approach
      } as GeneratePromptResponse),
      { headers: { ...corsHeaders, 'Content-Type': 'application/json' } }
    )

  } catch (error: any) {
    console.error('âŒ Error generating image prompt:', error)
    return new Response(
      JSON.stringify({
        success: false,
        error: error.message || 'Unknown error'
      } as GeneratePromptResponse),
      {
        status: 500,
        headers: { ...corsHeaders, 'Content-Type': 'application/json' },
      }
    )
  }
})

/**
 * LEVEL 1: Pre-Analyzer
 * Analyzes the article and decides which image generation approach to use
 */
async function runPreAnalyzer(supabase: any, title: string, content: string, selectedVariant?: PromptVariant): Promise<PreAnalyzerOutput | null> {
  try {
    // Get pre-analyzer prompt from database
    const { data: promptData } = await supabase
      .from('ai_prompts')
      .select('prompt_text')
      .eq('prompt_type', 'image_pre_analyzer')
      .eq('is_active', true)
      .order('updated_at', { ascending: false })
      .limit(1)
      .single()

    // Use default prompt if not found in database
    const preAnalyzerPrompt = promptData?.prompt_text || getDefaultPreAnalyzerPrompt()

    // Fill placeholders
    let filledPrompt = preAnalyzerPrompt
    filledPrompt = filledPrompt.replace(/{title}/g, title)
    filledPrompt = filledPrompt.replace(/{content}/g, content.substring(0, 3000))

    // Add selected variant guidance if provided
    if (selectedVariant) {
      filledPrompt += `\n\nâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
ĞĞ‘Ğ ĞĞĞ˜Ğ™ Ğ’Ğ†Ğ—Ğ£ĞĞ›Ğ¬ĞĞ˜Ğ™ ĞĞĞŸĞ Ğ¯ĞœĞĞš (ĞĞ‘ĞĞ’'Ğ¯Ğ—ĞšĞĞ’Ğ Ğ²Ğ¸ĞºĞ¾Ñ€Ğ¸ÑÑ‚Ğ°Ğ¹ ÑĞº Ğ¾ÑĞ½Ğ¾Ğ²Ñƒ):
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
ĞšĞ¾Ğ½Ñ†ĞµĞ¿Ñ†Ñ–Ñ: ${selectedVariant.label}
ĞĞ¿Ğ¸Ñ: ${selectedVariant.description}

Ğ‘Ğ°Ğ·ÑƒĞ¹ ÑĞ²Ñ–Ğ¹ Ğ°Ğ½Ğ°Ğ»Ñ–Ğ· Ğ½Ğ° Ñ†ÑŒĞ¾Ğ¼Ñƒ Ğ²Ñ–Ğ·ÑƒĞ°Ğ»ÑŒĞ½Ğ¾Ğ¼Ñƒ Ğ½Ğ°Ğ¿Ñ€ÑĞ¼ĞºÑƒ. visual_metaphor Ñ‚Ğ° core_idea Ğ¼Ğ°ÑÑ‚ÑŒ Ğ²Ñ–Ğ´Ğ¿Ğ¾Ğ²Ñ–Ğ´Ğ°Ñ‚Ğ¸ Ğ¾Ğ±Ñ€Ğ°Ğ½Ñ–Ğ¹ ĞºĞ¾Ğ½Ñ†ĞµĞ¿Ñ†Ñ–Ñ—.`
    }

    // Call Azure OpenAI
    const azureUrl = `${AZURE_OPENAI_ENDPOINT}/openai/deployments/Jobbot-gpt-4.1-mini/chat/completions?api-version=2024-02-15-preview`

    const response = await fetch(azureUrl, {
      method: 'POST',
      headers: {
        'Content-Type': 'application/json',
        'api-key': AZURE_OPENAI_API_KEY!
      },
      body: JSON.stringify({
        messages: [
          {
            role: 'system',
            content: 'You are a visual content strategist. Analyze articles and decide the best image approach. Respond with valid JSON only.'
          },
          { role: 'user', content: filledPrompt }
        ],
        temperature: 0.4,
        max_tokens: 500
      })
    })

    if (!response.ok) {
      console.error('âŒ Pre-Analyzer API error:', response.status)
      return null
    }

    const data = await response.json()
    let jsonString = data.choices[0]?.message?.content?.trim()

    if (!jsonString) return null

    // Clean up JSON
    jsonString = jsonString.replace(/```json\n?/g, '').replace(/```\n?/g, '').trim()

    try {
      const parsed = JSON.parse(jsonString) as PreAnalyzerOutput

      // Validate approach value
      const validApproaches = ['structured', 'creative', 'hero_image', 'artistic']
      if (!validApproaches.includes(parsed.approach)) {
        parsed.approach = 'creative' // Default to creative for variety
      }

      return parsed
    } catch (parseError) {
      console.error('âŒ Failed to parse Pre-Analyzer JSON:', parseError)
      return null
    }

  } catch (error: any) {
    console.error('âŒ Error running Pre-Analyzer:', error)
    return null
  }
}

/**
 * Default Pre-Analyzer prompt (used if not in database)
 */
function getDefaultPreAnalyzerPrompt(): string {
  return `ĞŸÑ€Ğ¾Ğ°Ğ½Ğ°Ğ»Ñ–Ğ·ÑƒĞ¹ Ñ†Ñ Ğ½Ğ¾Ğ²Ğ¸Ğ½Ñƒ Ñ– Ğ²Ğ¸Ğ·Ğ½Ğ°Ñ‡ ĞĞĞ™ĞšĞ ĞĞ©Ğ˜Ğ™ Ğ¿Ñ–Ğ´Ñ…Ñ–Ğ´ Ğ´Ğ»Ñ ÑÑ‚Ğ²Ğ¾Ñ€ĞµĞ½Ğ½Ñ Ğ·Ğ¾Ğ±Ñ€Ğ°Ğ¶ĞµĞ½Ğ½Ñ.

ĞĞĞ’Ğ˜ĞĞ:
Ğ—Ğ°Ğ³Ğ¾Ğ»Ğ¾Ğ²Ğ¾Ğº: {title}
Ğ—Ğ¼Ñ–ÑÑ‚: {content}

Ğ’Ğ˜Ğ‘Ğ•Ğ Ğ˜ ĞĞ”Ğ˜Ğ ĞŸĞ†Ğ”Ğ¥Ğ†Ğ”:

1. "structured" - Ğ†ĞĞ¤ĞĞ“Ğ ĞĞ¤Ğ†ĞšĞ (Ğ²Ğ¸ĞºĞ¾Ñ€Ğ¸ÑÑ‚Ğ¾Ğ²ÑƒĞ¹ Ğ¢Ğ†Ğ›Ğ¬ĞšĞ˜ ÑĞºÑ‰Ğ¾):
   - Ğ‘Ğ°Ğ³Ğ°Ñ‚Ğ¾ Ñ†Ğ¸Ñ„Ñ€, ÑÑ‚Ğ°Ñ‚Ğ¸ÑÑ‚Ğ¸ĞºĞ¸, Ğ¿Ğ¾Ñ€Ñ–Ğ²Ğ½ÑĞ½ÑŒ, Ğ³Ñ€Ğ°Ñ„Ñ–ĞºÑ–Ğ²
   - Ğ¡ĞºĞ»Ğ°Ğ´Ğ½Ğ¸Ğ¹ Ñ‚ĞµÑ…Ğ½Ñ–Ñ‡Ğ½Ğ¸Ğ¹ Ğ¿Ñ€Ğ¾Ñ†ĞµÑ Ñ‰Ğ¾ Ğ¿Ğ¾Ñ‚Ñ€ĞµĞ±ÑƒÑ” Ğ¿Ğ¾ÑÑĞ½ĞµĞ½Ğ½Ñ
   - Ğ¡Ğ¿Ğ¸ÑĞ¾Ğº 5+ Ñ„ÑƒĞ½ĞºÑ†Ñ–Ğ¹/Ğ¾ÑĞ¾Ğ±Ğ»Ğ¸Ğ²Ğ¾ÑÑ‚ĞµĞ¹ Ğ¿Ñ€Ğ¾Ğ´ÑƒĞºÑ‚Ñƒ
   - Ğ¤Ñ–Ğ½Ğ°Ğ½ÑĞ¾Ğ²Ñ– Ğ·Ğ²Ñ–Ñ‚Ğ¸, Ğ´Ğ¾ÑĞ»Ñ–Ğ´Ğ¶ĞµĞ½Ğ½Ñ Ğ· Ğ´Ğ°Ğ½Ğ¸Ğ¼Ğ¸

2. "creative" - Ğ£ĞĞ†ĞšĞĞ›Ğ¬ĞĞ• Ğ—ĞĞ‘Ğ ĞĞ–Ğ•ĞĞĞ¯ (Ğ²Ğ¸ĞºĞ¾Ñ€Ğ¸ÑÑ‚Ğ¾Ğ²ÑƒĞ¹ ÑĞºÑ‰Ğ¾):
   - ĞŸÑ€Ğ¾ÑÑ‚Ğ° Ğ½Ğ¾Ğ²Ğ¸Ğ½Ğ° Ğ¿Ñ€Ğ¾ Ğ°Ğ½Ğ¾Ğ½Ñ/Ğ¿Ğ¾Ğ´Ñ–Ñ
   - Ğ•Ğ¼Ğ¾Ñ†Ñ–Ğ¹Ğ½Ğ¸Ğ¹ ĞºĞ¾Ğ½Ñ‚ĞµĞ½Ñ‚ Ğ±ĞµĞ· ÑĞºĞ»Ğ°Ğ´Ğ½Ğ¸Ñ… Ğ´Ğ°Ğ½Ğ¸Ñ…
   - ĞœĞ¾Ğ¶Ğ½Ğ° Ğ¿ĞµÑ€ĞµĞ´Ğ°Ñ‚Ğ¸ ÑÑƒÑ‚ÑŒ Ğ¾Ğ´Ğ½Ğ¸Ğ¼ ÑÑĞºÑ€Ğ°Ğ²Ğ¸Ğ¼ Ğ¾Ğ±Ñ€Ğ°Ğ·Ğ¾Ğ¼

3. "hero_image" - Ğ¤ĞĞ¢Ğ-Ğ Ğ•ĞĞ›Ğ†Ğ¡Ğ¢Ğ˜Ğ§ĞĞ• (Ğ²Ğ¸ĞºĞ¾Ñ€Ğ¸ÑÑ‚Ğ¾Ğ²ÑƒĞ¹ ÑĞºÑ‰Ğ¾):
   - ĞŸĞ¾Ğ´Ğ¾Ñ€Ğ¾Ğ¶Ñ–, lifestyle, Ñ—Ğ¶Ğ°
   - Ğ¤Ñ–Ğ·Ğ¸Ñ‡Ğ½Ğ¸Ğ¹ Ğ¿Ñ€Ğ¾Ğ´ÑƒĞºÑ‚ ÑĞºĞ¸Ğ¹ Ğ¼Ğ¾Ğ¶Ğ½Ğ° Ğ¿Ğ¾ĞºĞ°Ğ·Ğ°Ñ‚Ğ¸
   - Ğ ĞµĞ°Ğ»ÑŒĞ½Ñ– Ğ»ÑĞ´Ğ¸, Ğ¼Ñ–ÑÑ†Ñ, Ğ¿Ğ¾Ğ´Ñ–Ñ—

4. "artistic" - Ğ¥Ğ£Ğ”ĞĞ–ĞĞ¯ Ğ†Ğ›Ğ®Ğ¡Ğ¢Ğ ĞĞ¦Ğ†Ğ¯ (Ğ²Ğ¸ĞºĞ¾Ñ€Ğ¸ÑÑ‚Ğ¾Ğ²ÑƒĞ¹ ÑĞºÑ‰Ğ¾):
   - ĞĞ±ÑÑ‚Ñ€Ğ°ĞºÑ‚Ğ½Ñ– ĞºĞ¾Ğ½Ñ†ĞµĞ¿Ñ†Ñ–Ñ— (AI, Ğ¼Ğ°Ğ¹Ğ±ÑƒÑ‚Ğ½Ñ”, Ñ–Ğ´ĞµÑ—)
   - Ğ¤Ñ–Ğ»Ğ¾ÑĞ¾Ñ„ÑÑŒĞºÑ–/ĞºÑƒĞ»ÑŒÑ‚ÑƒÑ€Ğ½Ñ– Ñ‚ĞµĞ¼Ğ¸
   - ĞšĞ¾Ğ»Ğ¸ Ğ¿Ğ¾Ñ‚Ñ€Ñ–Ğ±Ğ½Ğ° Ğ¼ĞµÑ‚Ğ°Ñ„Ğ¾Ñ€Ğ°

â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
Ğ Ğ•Ğ”ĞĞšĞ¢ĞĞ Ğ¡Ğ¬ĞšĞ˜Ğ™ ĞĞĞĞ›Ğ†Ğ— (ĞĞ‘ĞĞ’'Ğ¯Ğ—ĞšĞĞ’Ğ):
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

Ğ’Ğ¸Ğ·Ğ½Ğ°Ñ‡ ĞšĞ›Ğ®Ğ§ĞĞ’Ğ£ Ğ†Ğ”Ğ•Ğ® ÑÑ‚Ğ°Ñ‚Ñ‚Ñ–:
- Ğ¦Ğµ ĞĞ• Ñ‚ĞµĞ¼Ğ° Ñ– ĞĞ• Ñ„Ğ°ĞºÑ‚Ğ¸. Ğ¦Ğµ Ğ¡Ğ£Ğ¢Ğ¬ â€” Ñ‰Ğ¾ Ğ·Ğ¼Ñ–Ğ½ÑÑ”Ñ‚ÑŒÑÑ, Ñ‰Ğ¾ Ğ· Ñ‡Ğ¸Ğ¼ ĞºĞ¾Ğ½Ñ„Ğ»Ñ–ĞºÑ‚ÑƒÑ”, Ñ‰Ğ¾ Ğ½Ğ°Ñ€Ğ¾Ğ´Ğ¶ÑƒÑ”Ñ‚ÑŒÑÑ.
- Ğ¤Ğ¾Ñ€Ğ¼Ğ°Ñ‚: "X â†’ Y" (Ñ‚Ñ€Ğ°Ğ½ÑÑ„Ğ¾Ñ€Ğ¼Ğ°Ñ†Ñ–Ñ), "X vs Y" (ĞºĞ¾Ğ½Ñ„Ğ»Ñ–ĞºÑ‚), "X = Y" (Ğ½ĞµÑĞ¿Ğ¾Ğ´Ñ–Ğ²Ğ°Ğ½Ğµ Ğ¿Ğ¾Ñ€Ñ–Ğ²Ğ½ÑĞ½Ğ½Ñ)
- ĞŸÑ€Ğ¸ĞºĞ»Ğ°Ğ´Ğ¸:
  * "ĞĞ¾Ñ€Ğ²ĞµĞ·ÑŒĞºĞ¸Ğ¹ ÑÑ‚Ğ°Ñ€Ñ‚Ğ°Ğ¿ Ğ²Ğ¸Ğ³Ñ€Ğ°Ğ² ĞºĞ¾Ğ½Ñ‚Ñ€Ğ°ĞºÑ‚" â†’ "Ğ¼Ğ°Ğ»ĞµĞ½ÑŒĞºĞ° Ñ€Ğ¸Ğ±Ğ° Ğ¿ĞµÑ€ĞµĞ¼Ğ°Ğ³Ğ°Ñ” Ğ¾ĞºĞµĞ°Ğ½"
  * "AI Ğ·Ğ°Ğ¼Ñ–Ğ½ÑÑ” Ğ¿Ñ€Ğ¾Ğ³Ñ€Ğ°Ğ¼Ñ–ÑÑ‚Ñ–Ğ²" â†’ "Ñ–Ğ½ÑÑ‚Ñ€ÑƒĞ¼ĞµĞ½Ñ‚ Ğ·'Ñ—Ğ´Ğ°Ñ” ÑĞ²Ğ¾Ğ³Ğ¾ Ñ‚Ğ²Ğ¾Ñ€Ñ†Ñ"
  * "Highsoft Ğ¾Ñ‚Ñ€Ğ¸Ğ¼Ğ°Ğ² $40M" â†’ "Ğ½ĞµĞ²Ğ¸Ğ´Ğ¸Ğ¼Ğ¸Ğ¹ Ñ„ÑƒĞ½Ğ´Ğ°Ğ¼ĞµĞ½Ñ‚ ÑÑ‚Ğ°Ñ” Ğ²Ğ¸Ğ´Ğ¸Ğ¼Ğ¸Ğ¼"

Ğ’Ğ¸Ğ·Ğ½Ğ°Ñ‡ Ğ¤Ğ†Ğ—Ğ˜Ğ§ĞĞ£ ĞœĞ•Ğ¢ĞĞ¤ĞĞ Ğ£ Ğ´Ğ»Ñ Ñ–Ğ´ĞµÑ—:
- ĞšĞ°Ñ‚ĞµĞ³Ğ¾Ñ€Ñ–Ñ— Ğ¼ĞµÑ‚Ğ°Ñ„Ğ¾Ñ€:
  * ĞĞ Ğ¥Ğ†Ğ¢Ğ•ĞšĞ¢Ğ£Ğ ĞĞ: Ğ¼Ğ¾ÑÑ‚Ğ¸, Ñ„ÑƒĞ½Ğ´Ğ°Ğ¼ĞµĞ½Ñ‚Ğ¸, Ğ²ĞµĞ¶Ñ–, Ğ°Ñ€ĞºĞ¸, Ñ€ÑƒÑ—Ğ½Ğ¸
  * ĞŸĞ Ğ˜Ğ ĞĞ”ĞĞ: ĞºĞ¾Ñ€Ñ–Ğ½Ğ½Ñ, Ñ€Ñ–ĞºĞ¸, ĞºÑ€Ğ¸ÑÑ‚Ğ°Ğ»Ğ¸, Ğ²ÑƒĞ»ĞºĞ°Ğ½Ğ¸, Ğ»ÑŒĞ¾Ğ´Ğ¾Ğ²Ğ¸ĞºĞ¸
  * ĞšĞĞĞ¤Ğ›Ğ†ĞšĞ¢: Ğ·Ñ–Ñ‚ĞºĞ½ĞµĞ½Ğ½Ñ, Ğ±Ğ°Ğ»Ğ°Ğ½Ñ, Ñ‚Ğ¸ÑĞº, Ñ€Ğ¾Ğ·Ñ€Ğ¸Ğ², Ğ·Ğ»Ğ°Ğ¼
  * Ğ¡Ğ˜Ğ¡Ğ¢Ğ•ĞœĞĞ: Ğ¼ĞµÑ…Ğ°Ğ½Ñ–Ğ·Ğ¼Ğ¸, Ğ¿Ğ¾Ñ‚Ğ¾ĞºĞ¸, Ğ¼ĞµÑ€ĞµĞ¶Ñ–, Ğ»Ğ°Ğ½Ñ†ÑĞ³Ğ¸, Ğ¾Ñ€Ğ±Ñ–Ñ‚Ğ¸
- ĞœĞµÑ‚Ğ°Ñ„Ğ¾Ñ€Ğ° Ğ¼Ğ°Ñ” Ğ±ÑƒÑ‚Ğ¸ Ğ¤Ğ†Ğ—Ğ˜Ğ§ĞĞĞ® (Ñ‚Ğµ Ñ‰Ğ¾ Ğ¼Ğ¾Ğ¶Ğ½Ğ° Ğ¿Ğ¾Ğ±Ğ°Ñ‡Ğ¸Ñ‚Ğ¸ Ñ– Ğ½Ğ°Ğ¼Ğ°Ğ»ÑĞ²Ğ°Ñ‚Ğ¸)
- ĞĞ• Ğ°Ğ±ÑÑ‚Ñ€Ğ°ĞºÑ‚Ğ½Ğ° ("Ñ–Ğ½Ğ½Ğ¾Ğ²Ğ°Ñ†Ñ–Ñ"), Ğ° ĞºĞ¾Ğ½ĞºÑ€ĞµÑ‚Ğ½Ğ° ("ĞºÑ€Ğ¸ÑÑ‚Ğ°Ğ» Ñ‰Ğ¾ Ñ€Ğ¾ÑÑ‚Ğµ Ğ· Ñ‚Ñ€Ñ–Ñ‰Ğ¸Ğ½Ğ¸ Ğ² ÑĞºĞµĞ»Ñ–")

ĞŸĞ¾Ğ²ĞµÑ€Ğ½Ğ¸ JSON:
{
  "approach": "structured" | "creative" | "hero_image" | "artistic",
  "mood": "Ğ¾Ğ¿Ğ¸Ñ Ğ½Ğ°ÑÑ‚Ñ€Ğ¾Ñ (excited, serious, hopeful, dramatic...)",
  "complexity": "simple" | "medium" | "complex",
  "reason": "Ñ‡Ğ¾Ğ¼Ñƒ Ğ¾Ğ±Ñ€Ğ°Ğ² Ñ†ĞµĞ¹ Ğ¿Ñ–Ğ´Ñ…Ñ–Ğ´ (1 Ñ€ĞµÑ‡ĞµĞ½Ğ½Ñ)",
  "suggested_style": "ĞºĞ¾Ğ½ĞºÑ€ĞµÑ‚Ğ½Ğ¸Ğ¹ ÑÑ‚Ğ¸Ğ»ÑŒ (cinematic, minimalist, vibrant...)",
  "color_mood": "Ñ‚ĞµĞ¿Ğ»Ñ–/Ñ…Ğ¾Ğ»Ğ¾Ğ´Ğ½Ñ–/Ğ½ĞµĞ¹Ñ‚Ñ€Ğ°Ğ»ÑŒĞ½Ñ– + Ğ³Ğ¾Ğ»Ğ¾Ğ²Ğ½Ğ¸Ğ¹ ĞºĞ¾Ğ»Ñ–Ñ€",
  "key_emotion": "Ğ³Ğ¾Ğ»Ğ¾Ğ²Ğ½Ğ° ĞµĞ¼Ğ¾Ñ†Ñ–Ñ ÑĞºÑƒ Ğ¼Ğ°Ñ” Ğ²Ğ¸ĞºĞ»Ğ¸ĞºĞ°Ñ‚Ğ¸ Ğ·Ğ¾Ğ±Ñ€Ğ°Ğ¶ĞµĞ½Ğ½Ñ",
  "core_idea": "ĞºĞ»ÑÑ‡Ğ¾Ğ²Ğ° Ñ–Ğ´ĞµÑ Ñƒ Ñ„Ğ¾Ñ€Ğ¼Ğ°Ñ‚Ñ– X â†’ Y / X vs Y / X = Y",
  "visual_metaphor": "ĞºĞ¾Ğ½ĞºÑ€ĞµÑ‚Ğ½Ğ° Ñ„Ñ–Ğ·Ğ¸Ñ‡Ğ½Ğ° Ğ¼ĞµÑ‚Ğ°Ñ„Ğ¾Ñ€Ğ° (1 Ñ€ĞµÑ‡ĞµĞ½Ğ½Ñ)"
}`
}

/**
 * CREATIVE APPROACH: Generate unique prompt without templates
 */
async function generateCreativePrompt(
  supabase: any,
  title: string,
  content: string,
  preAnalysis: PreAnalyzerOutput,
  selectedVariant?: PromptVariant
): Promise<string | null> {
  try {
    // Get creative writer prompt from database
    const { data: promptData } = await supabase
      .from('ai_prompts')
      .select('prompt_text')
      .eq('prompt_type', 'image_creative_writer')
      .eq('is_active', true)
      .order('updated_at', { ascending: false })
      .limit(1)
      .single()

    // Use default prompt if not found
    const creativePrompt = promptData?.prompt_text || getDefaultCreativeWriterPrompt()

    // Fill placeholders
    let filledPrompt = creativePrompt
    filledPrompt = filledPrompt.replace(/{title}/g, title)
    filledPrompt = filledPrompt.replace(/{content}/g, content.substring(0, 2000))
    filledPrompt = filledPrompt.replace(/{approach}/g, preAnalysis.approach)
    filledPrompt = filledPrompt.replace(/{mood}/g, preAnalysis.mood)
    filledPrompt = filledPrompt.replace(/{suggested_style}/g, preAnalysis.suggested_style)
    filledPrompt = filledPrompt.replace(/{color_mood}/g, preAnalysis.color_mood)
    filledPrompt = filledPrompt.replace(/{key_emotion}/g, preAnalysis.key_emotion)
    filledPrompt = filledPrompt.replace(/{complexity}/g, preAnalysis.complexity)
    filledPrompt = filledPrompt.replace(/{core_idea}/g, preAnalysis.core_idea || 'Not provided')
    filledPrompt = filledPrompt.replace(/{visual_metaphor}/g, preAnalysis.visual_metaphor || 'Not provided')

    // Add selected variant guidance if provided
    if (selectedVariant) {
      filledPrompt += `\n\nâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
SELECTED VISUAL CONCEPT (expand this into a detailed image prompt):
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
Concept: ${selectedVariant.label}
Description: ${selectedVariant.description}

Expand this surreal concept into a rich, detailed prompt. Keep the style scene as the dominant visual. Enrich with specific details, lighting, textures, and composition.`
      // No separate style section needed - style IS the description
    }

    // Call Azure OpenAI
    const azureUrl = `${AZURE_OPENAI_ENDPOINT}/openai/deployments/Jobbot-gpt-4.1-mini/chat/completions?api-version=2024-02-15-preview`

    const systemContent = selectedVariant
      ? `You are a surrealist image prompt writer. You receive a visual concept that combines a random style scene with an article keyword.

Your job: Expand this concept into a rich, detailed image generation prompt (150-250 words).

RULES:
- The concept IS the scene. Do NOT replace it with something "professional" or "editorial"
- PRESERVE the surreal, unexpected, scroll-stopping nature
- ADD: specific lighting, camera angle, lens, color palette, atmosphere details
- ADD: textures, materials, depth of field, composition
- KEEP the article keyword element prominent but natural
- Write in English
- Do NOT add people sitting at desks, office scenes, or stock-photo clichÃ©s`
      : `You are an editorial art director who thinks in METAPHORS, not scenes.
Your method: Idea â†’ Metaphor â†’ Tension â†’ Style.

RULES:
- NEVER describe literal scenes (people in offices, meetings, screens, handshakes)
- NEVER use generic stock-photo compositions (group of people, person at laptop, city skyline)
- ALWAYS build on the provided core_idea and visual_metaphor from the pre-analysis
- Think architecturally: structures, mechanisms, forces, contrasts
- Add TENSION or MOVEMENT: growth, collision, balance, transformation, scale shift
- Give CONSTRAINTS not details: limit the palette, force asymmetry, demand one focal point
- Write in English. Be specific and visual.`

    const response = await fetch(azureUrl, {
      method: 'POST',
      headers: {
        'Content-Type': 'application/json',
        'api-key': AZURE_OPENAI_API_KEY!
      },
      body: JSON.stringify({
        messages: [
          {
            role: 'system',
            content: systemContent
          },
          { role: 'user', content: filledPrompt }
        ],
        temperature: 0.7, // Higher temperature for creativity
        max_tokens: 800
      })
    })

    if (!response.ok) {
      console.error('âŒ Creative Writer API error:', response.status)
      return null
    }

    const data = await response.json()
    const generatedPrompt = data.choices[0]?.message?.content?.trim()

    if (!generatedPrompt) return null

    // Add quality boost and branding to the creative prompt
    const qualityBoost = `

QUALITY REQUIREMENTS (MANDATORY):
- Ultra high resolution, 8K quality
- Vibrant colors with professional contrast
- Sharp details, no blur or artifacts
- Professional lighting with depth
- 1:1 square aspect ratio for social media

BRANDING (MANDATORY):
- Add small "vitalii.no" watermark text in the bottom right corner
- The watermark should be subtle but readable`

    return generatedPrompt + qualityBoost

  } catch (error: any) {
    console.error('âŒ Error generating creative prompt:', error)
    return null
  }
}

/**
 * Default Creative Writer prompt (used if not in database)
 */
function getDefaultCreativeWriterPrompt(): string {
  return `You are creating an image prompt for a news article. Follow the EDITORIAL METHOD strictly.

ARTICLE:
{title}

{content}

PRE-ANALYSIS:
- Approach: {approach}
- Mood: {mood}
- Style: {suggested_style}
- Colors: {color_mood}
- Emotion: {key_emotion}
- Complexity: {complexity}
- Core Idea: {core_idea}
- Visual Metaphor: {visual_metaphor}

â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
EDITORIAL METHOD â€” Follow these 4 steps:
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

STEP 1 â€” IDEA:
Take the core_idea from pre-analysis. If it's weak or missing, extract the ESSENCE yourself:
What is TRANSFORMING? What is in CONFLICT? What SURPRISING connection exists?
Format: "X â†’ Y" or "X vs Y" or "X = Y"

STEP 2 â€” METAPHOR:
Take the visual_metaphor from pre-analysis and develop it into a CONCRETE visual image.
Make it PHYSICAL â€” something you can photograph or sculpt:
- Architecture: bridges, foundations, towers, arches, ruins, scaffolding
- Nature: roots, rivers, crystals, volcanoes, glaciers, tectonic plates
- Mechanisms: gears, pendulums, pressure valves, chain reactions
- Forces: collision, erosion, crystallization, magnetism, gravity

STEP 3 â€” TENSION / MOVEMENT:
Add ONE dynamic force to the metaphor:
- GROWTH: something emerging, sprouting, rising, expanding
- COLLISION: two forces meeting, friction, impact
- BALANCE: precarious equilibrium, tipping point
- TRANSFORMATION: melting, crystallizing, metamorphosis
- SCALE SHIFT: microscopic vs cosmic, detail vs panorama

STEP 4 â€” STYLE & CONSTRAINTS:
- Limit palette to 2-3 colors maximum
- Force ONE focal point (not a busy scene)
- Choose rendering: cinematic photography, architectural visualization, macro photography, or editorial illustration
- Add lighting direction and atmosphere

â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
FORBIDDEN (never include):
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
- People sitting at desks, tables, or meetings
- Office scenes, conference rooms, coworking spaces
- Generic cityscapes or skylines
- Hands shaking, thumbs up, people pointing at screens
- Laptops, phones, or screens showing content
- Groups of smiling professionals
- Any stock-photo clichÃ© composition

â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
EXAMPLE:
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
Article: "Highsoft from Vik raises $40M for data visualization"
Core idea: "invisible infrastructure becomes visible"
Metaphor: "crystalline data structure rising from a fjord village"
Result: "A massive translucent crystalline structure emerges from between traditional Norwegian wooden houses in a narrow fjord valley. The crystal facets refract morning light into data-like patterns on the mountain walls. Fog rolls through the valley at the crystal's base. Cinematic wide shot, cool Nordic blue palette with warm amber refractions. Architectural visualization style, dramatic scale contrast between tiny village and towering crystal formation."

Write the image prompt in English (150-250 words):`
}

/**
 * Generate 4 visual concept variants for moderator to choose from
 */
async function generateVariants(supabase: any, title: string, content: string): Promise<PromptVariant[] | null> {
  try {
    // Pick a random style prompt to add unique visual direction
    const stylePrompt = getRandomStylePrompt()
    console.log(`ğŸ¨ Selected style prompt: ${stylePrompt.substring(0, 100)}...`)

    // Build prompt with style as PRIMARY and article for keyword extraction
    const filledPrompt = `STYLE SCENE (this is the PRIMARY visual, 70-80% of the image):
${stylePrompt}

ARTICLE (extract ONE keyword/concept to integrate):
Title: ${title}
Content: ${content.substring(0, 2000)}

Create 4 variants where the STYLE SCENE is the base, and one keyword from the article is naturally woven in as a recognizable element.

For each variant provide:
- label: short title (3-5 words, mentions both the style and article topic)
- description: scene description where style IS the base and article element is woven in naturally (2-3 sentences)

JSON array:`

    // Call Azure OpenAI
    const azureUrl = `${AZURE_OPENAI_ENDPOINT}/openai/deployments/Jobbot-gpt-4.1-mini/chat/completions?api-version=2024-02-15-preview`

    const response = await fetch(azureUrl, {
      method: 'POST',
      headers: {
        'Content-Type': 'application/json',
        'api-key': AZURE_OPENAI_API_KEY!
      },
      body: JSON.stringify({
        messages: [
          {
            role: 'system',
            content: `You are a surrealist art director creating scroll-stopping viral images.
You receive TWO inputs:
1. STYLE SCENE â€” this is the PRIMARY visual (70-80% of the image). This IS the scene.
2. ARTICLE KEYWORD â€” ONE word/concept extracted from the article. This is the easter egg (20-30%).

Your job: Create 4 variants where the STYLE SCENE is the dominant visual, and the ARTICLE KEYWORD is naturally woven in as a recognizable element.

EXAMPLE:
Style: "baby yoda eating cheeseburger from McDonald's, hyper realistic..."
Article keyword: "Router" (from article about OpenRouter)
Result: "Hyperrealistic baby Yoda at McDonald's eating a cheeseburger. On the table next to him sits a glowing futuristic WiFi router projecting holographic AI model names into the air above. Same hyper-detailed style, same McDonald's setting, but with this one tech element that ties it to the article."

RULES:
- The style scene IS the image. Don't replace it.
- The article keyword should feel like a natural part of the scene, not forced
- Each variant should integrate the keyword DIFFERENTLY (as an object, background element, reflection, texture, etc.)
- Keep all technical quality parameters from the style prompt
- Respond ONLY with valid JSON array, no markdown formatting`
          },
          { role: 'user', content: filledPrompt }
        ],
        temperature: 0.8,
        max_tokens: 1500
      })
    })

    if (!response.ok) {
      console.error('âŒ Variants API error:', response.status)
      return null
    }

    const data = await response.json()
    let jsonString = data.choices[0]?.message?.content?.trim()

    if (!jsonString) return null

    // Clean up JSON
    jsonString = jsonString.replace(/```json\n?/g, '').replace(/```\n?/g, '').trim()

    try {
      const parsed = JSON.parse(jsonString)

      // Validate it's an array of variants
      if (!Array.isArray(parsed) || parsed.length === 0) {
        console.error('âŒ Variants response is not a valid array')
        return null
      }

      // Ensure exactly 4 variants, validate structure, store stylePrompt for reference
      const variants: PromptVariant[] = parsed
        .filter((v: any) => v.label && v.description)
        .slice(0, 4)
        .map((v: any) => ({
          label: String(v.label).substring(0, 50),
          description: String(v.description),
          stylePrompt: stylePrompt,
        }))

      if (variants.length < 2) {
        console.error('âŒ Too few valid variants:', variants.length)
        return null
      }

      return variants
    } catch (parseError) {
      console.error('âŒ Failed to parse variants JSON:', parseError)
      return null
    }
  } catch (error: any) {
    console.error('âŒ Error generating variants:', error)
    return null
  }
}

/**
 * Default prompt for generating 4 visual concept variants
 */
function getDefaultVariantsPrompt(): string {
  return `Ğ¢Ğ¸ â€” Ğ°Ñ€Ñ‚-Ğ´Ğ¸Ñ€ĞµĞºÑ‚Ğ¾Ñ€ Ğ¿Ñ€ĞµĞ¼Ñ–Ğ°Ğ»ÑŒĞ½Ğ¾Ğ³Ğ¾ Ğ½Ğ¾Ğ²Ğ¸Ğ½Ğ½Ğ¾Ğ³Ğ¾ Ğ²Ğ¸Ğ´Ğ°Ğ½Ğ½Ñ. ĞŸÑ€Ğ¾Ñ‡Ğ¸Ñ‚Ğ°Ğ¹ ÑÑ‚Ğ°Ñ‚Ñ‚Ñ Ñ‚Ğ° Ğ·Ğ°Ğ¿Ñ€Ğ¾Ğ¿Ğ¾Ğ½ÑƒĞ¹ 4 Ğ Ğ†Ğ—ĞĞ˜Ğ¥ Ğ¤ĞĞ¢ĞĞ Ğ•ĞĞ›Ğ†Ğ¡Ğ¢Ğ˜Ğ§ĞĞ˜Ğ¥ 4K Ğ²Ñ–Ğ·ÑƒĞ°Ğ»ÑŒĞ½Ğ¸Ñ… ĞºĞ¾Ğ½Ñ†ĞµĞ¿Ñ†Ñ–Ğ¹ Ğ´Ğ»Ñ Ñ–Ğ»ÑÑÑ‚Ñ€Ğ°Ñ†Ñ–Ñ—.

Ğ¡Ğ¢ĞĞ¢Ğ¢Ğ¯:
Ğ—Ğ°Ğ³Ğ¾Ğ»Ğ¾Ğ²Ğ¾Ğº: {title}
Ğ—Ğ¼Ñ–ÑÑ‚: {content}

â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
ĞĞ‘ĞĞ’'Ğ¯Ğ—ĞšĞĞ’Ğ† ĞŸĞ ĞĞ’Ğ˜Ğ›Ğ:
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
1. ĞšĞ¾Ğ¶Ğ½Ğ° ĞºĞ¾Ğ½Ñ†ĞµĞ¿Ñ†Ñ–Ñ ĞĞ‘ĞĞ’'Ğ¯Ğ—ĞšĞĞ’Ğ Ğ¼Ğ°Ñ” Ğ·Ğ³Ğ°Ğ´ÑƒĞ²Ğ°Ñ‚Ğ¸ ĞºĞ¾Ğ½ĞºÑ€ĞµÑ‚Ğ½Ñ– Ğ½Ğ°Ğ·Ğ²Ğ¸, ĞºĞ¾Ğ¼Ğ¿Ğ°Ğ½Ñ–Ñ—, Ğ¿Ñ€Ğ¾Ğ´ÑƒĞºÑ‚Ğ¸ Ğ°Ğ±Ğ¾ Ñ‚ĞµÑ…Ğ½Ğ¾Ğ»Ğ¾Ğ³Ñ–Ñ— Ğ·Ñ– ÑÑ‚Ğ°Ñ‚Ñ‚Ñ–
2. Ğ’ÑÑ– 4 ĞºĞ¾Ğ½Ñ†ĞµĞ¿Ñ†Ñ–Ñ— â€” Ğ¤ĞĞ¢ĞĞ Ğ•ĞĞ›Ğ†Ğ¡Ğ¢Ğ˜Ğ§ĞĞ† 4K ÑÑ†ĞµĞ½Ğ¸ (ĞºÑ–Ğ½ĞµĞ¼Ğ°Ñ‚Ğ¾Ğ³Ñ€Ğ°Ñ„Ñ–Ñ‡Ğ½Ğ° ÑĞºÑ–ÑÑ‚ÑŒ, ÑĞº Ğ·Ğ½ÑÑ‚Ğµ Ğ¿Ñ€Ğ¾Ñ„ĞµÑÑ–Ğ¹Ğ½Ğ¸Ğ¼ Ñ„Ğ¾Ñ‚Ğ¾Ğ³Ñ€Ğ°Ñ„Ğ¾Ğ¼)
3. Ğ—ĞĞ‘ĞĞ ĞĞĞ•ĞĞ: Ğ°Ğ±ÑÑ‚Ñ€Ğ°ĞºÑ‚Ğ½Ñ– ÑĞ¸Ğ¼Ğ²Ğ¾Ğ»Ğ¸, Ğ¿Ñ€Ğ¾ÑÑ‚Ñ– Ñ–Ğ»ÑÑÑ‚Ñ€Ğ°Ñ†Ñ–Ñ—, Ğ·Ğ°Ğ³Ğ°Ğ»ÑŒĞ½Ñ– Ğ¾Ğ±Ñ€Ğ°Ğ·Ğ¸ Ğ±ĞµĞ· Ğ¿Ñ€Ğ¸Ğ²'ÑĞ·ĞºĞ¸ Ğ´Ğ¾ ÑÑ‚Ğ°Ñ‚Ñ‚Ñ–
4. ĞšĞ¾Ğ¶ĞµĞ½ Ğ¾Ğ¿Ğ¸Ñ Ğ¼Ğ°Ñ” Ğ¼Ğ°Ğ»ÑĞ²Ğ°Ñ‚Ğ¸ ĞºĞ¾Ğ½ĞºÑ€ĞµÑ‚Ğ½Ñƒ Ğ²Ñ–Ğ·ÑƒĞ°Ğ»ÑŒĞ½Ñƒ ÑÑ†ĞµĞ½Ñƒ Ğ· Ğ¾ÑĞ²Ñ–Ñ‚Ğ»ĞµĞ½Ğ½ÑĞ¼, ĞºĞ¾Ğ¼Ğ¿Ğ¾Ğ·Ğ¸Ñ†Ñ–Ñ”Ñ Ñ‚Ğ° Ğ°Ñ‚Ğ¼Ğ¾ÑÑ„ĞµÑ€Ğ¾Ñ

â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
4 ĞšĞĞ¢Ğ•Ğ“ĞĞ Ğ†Ğ‡ ĞšĞĞĞ¦Ğ•ĞŸĞ¦Ğ†Ğ™:
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
1. Ğ¤ĞĞ¢ĞĞ Ğ•ĞĞ›Ğ†Ğ¡Ğ¢Ğ˜Ğ§ĞĞ ĞœĞ•Ğ¢ĞĞ¤ĞĞ Ğ Ğ· Ğ¿Ñ€Ğ¾Ğ´ÑƒĞºÑ‚Ğ¾Ğ¼/Ñ‚ĞµÑ…Ğ½Ğ¾Ğ»Ğ¾Ğ³Ñ–Ñ”Ñ â€” ĞºÑ–Ğ½ĞµĞ¼Ğ°Ñ‚Ğ¾Ğ³Ñ€Ğ°Ñ„Ñ–Ñ‡Ğ½Ğ° ÑÑ†ĞµĞ½Ğ° Ğ´Ğµ Ñ‚ĞµĞ¼Ğ° ÑÑ‚Ğ°Ñ‚Ñ‚Ñ– Ğ¿Ğ¾ĞºĞ°Ğ·Ğ°Ğ½Ğ° Ñ‡ĞµÑ€ĞµĞ· Ğ¿Ğ¾Ñ‚ÑƒĞ¶Ğ½Ñƒ Ğ²Ñ–Ğ·ÑƒĞ°Ğ»ÑŒĞ½Ñƒ Ğ¼ĞµÑ‚Ğ°Ñ„Ğ¾Ñ€Ñƒ. ĞĞ±Ğ¾Ğ²'ÑĞ·ĞºĞ¾Ğ²Ğ¾ Ğ²ĞºĞ»ÑÑ‡Ğ¸Ñ‚Ğ¸ ĞºĞ¾Ğ½ĞºÑ€ĞµÑ‚Ğ½Ñƒ Ğ½Ğ°Ğ·Ğ²Ñƒ Ğ¿Ñ€Ğ¾Ğ´ÑƒĞºÑ‚Ñƒ/ĞºĞ¾Ğ¼Ğ¿Ğ°Ğ½Ñ–Ñ—.
2. Ğ¢Ğ•Ğ¥ĞĞĞ›ĞĞ“Ğ†Ğ§ĞĞ/Ğ†ĞĞ”Ğ£Ğ¡Ğ¢Ğ Ğ†ĞĞ›Ğ¬ĞĞ Ğ²Ñ–Ğ·ÑƒĞ°Ğ»Ñ–Ğ·Ğ°Ñ†Ñ–Ñ â€” Ğ¿Ğ¾ĞºĞ°Ğ·Ğ°Ñ‚Ğ¸ Ñ‚ĞµÑ…Ğ½Ğ¾Ğ»Ğ¾Ğ³Ñ–Ñ, Ğ¾Ğ±Ğ»Ğ°Ğ´Ğ½Ğ°Ğ½Ğ½Ñ, Ñ–Ğ½Ñ„Ñ€Ğ°ÑÑ‚Ñ€ÑƒĞºÑ‚ÑƒÑ€Ñƒ Ñ‡Ğ¸ ÑĞ¸ÑÑ‚ĞµĞ¼Ñƒ Ğ¾Ğ¿Ğ¸ÑĞ°Ğ½Ñƒ Ğ² ÑÑ‚Ğ°Ñ‚Ñ‚Ñ–. Ğ¤Ğ¾Ñ‚Ğ¾Ñ€ĞµĞ°Ğ»Ñ–ÑÑ‚Ğ¸Ñ‡Ğ½Ğ¸Ğ¹ Ñ€ĞµĞ½Ğ´ĞµÑ€ Ñ€ĞµĞ°Ğ»ÑŒĞ½Ğ¾Ğ³Ğ¾ Ğ¿Ñ€Ğ¾Ğ´ÑƒĞºÑ‚Ñƒ/Ñ‚ĞµÑ…Ğ½Ğ¾Ğ»Ğ¾Ğ³Ñ–Ñ—.
3. ĞšĞ†ĞĞ•ĞœĞĞ¢ĞĞ“Ğ ĞĞ¤Ğ†Ğ§ĞĞ Ğ”Ğ ĞĞœĞĞ¢Ğ˜Ğ§ĞĞ ÑÑ†ĞµĞ½Ğ° â€” editorial Ñ„Ğ¾Ñ‚Ğ¾Ğ³Ñ€Ğ°Ñ„Ñ–Ñ Ñ‰Ğ¾ Ğ¿ĞµÑ€ĞµĞ´Ğ°Ñ” Ğ’ĞŸĞ›Ğ˜Ğ’ Ñ‡Ğ¸ ĞĞĞ¡Ğ›Ğ†Ğ”ĞšĞ˜ Ğ¾Ğ¿Ğ¸ÑĞ°Ğ½Ğ¾Ğ³Ğ¾ Ğ² ÑÑ‚Ğ°Ñ‚Ñ‚Ñ–. Ğ›ÑĞ´ÑÑŒĞºĞ¸Ğ¹ Ğ¼Ğ°ÑÑˆÑ‚Ğ°Ğ±, Ğ´Ñ€Ğ°Ğ¼Ğ°Ñ‚Ğ¸Ñ‡Ğ½Ğµ Ğ¾ÑĞ²Ñ–Ñ‚Ğ»ĞµĞ½Ğ½Ñ.
4. ĞœĞĞšĞ ĞĞ—Ğ™ĞĞœĞšĞ Ğ”Ğ•Ğ¢ĞĞ›Ğ† â€” ĞµĞºÑÑ‚Ñ€ĞµĞ¼Ğ°Ğ»ÑŒĞ½Ğ¸Ğ¹ ĞºÑ€ÑƒĞ¿Ğ½Ğ¸Ğ¹ Ğ¿Ğ»Ğ°Ğ½ ĞºĞ»ÑÑ‡Ğ¾Ğ²Ğ¾Ğ³Ğ¾ ĞµĞ»ĞµĞ¼ĞµĞ½Ñ‚Ñƒ Ğ·Ñ– ÑÑ‚Ğ°Ñ‚Ñ‚Ñ–. ĞœĞ°Ğ»Ğ° Ğ³Ğ»Ğ¸Ğ±Ğ¸Ğ½Ğ° Ñ€Ñ–Ğ·ĞºĞ¾ÑÑ‚Ñ–, Ñ‚ĞµĞºÑÑ‚ÑƒÑ€Ğ° Ñ‚Ğ° Ğ´ĞµÑ‚Ğ°Ğ»Ñ– Ğ¿Ñ€ĞµĞ´Ğ¼ĞµÑ‚Ğ°.

Ğ”Ğ»Ñ ĞºĞ¾Ğ¶Ğ½Ğ¾Ñ— ĞºĞ¾Ğ½Ñ†ĞµĞ¿Ñ†Ñ–Ñ— Ğ´Ğ°Ğ¹:
- label: ĞºĞ¾Ñ€Ğ¾Ñ‚ĞºĞ¸Ğ¹ Ğ·Ğ°Ğ³Ğ¾Ğ»Ğ¾Ğ²Ğ¾Ğº (3-5 ÑĞ»Ñ–Ğ², ĞĞ‘ĞĞ’'Ğ¯Ğ—ĞšĞĞ’Ğ Ğ·Ğ³Ğ°Ğ´ÑƒÑ” Ñ‚ĞµĞ¼Ñƒ ÑÑ‚Ğ°Ñ‚Ñ‚Ñ–)
- description: Ğ¾Ğ¿Ğ¸Ñ Ñ„Ğ¾Ñ‚Ğ¾Ñ€ĞµĞ°Ğ»Ñ–ÑÑ‚Ğ¸Ñ‡Ğ½Ğ¾Ñ— ÑÑ†ĞµĞ½Ğ¸ (2-3 Ñ€ĞµÑ‡ĞµĞ½Ğ½Ñ Ğ· ĞºĞ¾Ğ½ĞºÑ€ĞµÑ‚Ğ½Ğ¸Ğ¼Ğ¸ Ğ´ĞµÑ‚Ğ°Ğ»ÑĞ¼Ğ¸, Ğ¾ÑĞ²Ñ–Ñ‚Ğ»ĞµĞ½Ğ½ÑĞ¼, Ñ€Ğ°ĞºÑƒÑ€ÑĞ¾Ğ¼ ĞºĞ°Ğ¼ĞµÑ€Ğ¸)

â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
ĞŸĞ Ğ˜ĞšĞ›ĞĞ” (ÑÑ‚Ğ°Ñ‚Ñ‚Ñ Ğ¿Ñ€Ğ¾ "OpenAI Trusted Access for Cyber"):
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
[
  {"label": "ĞšÑ–Ğ±ĞµÑ€Ñ‰Ğ¸Ñ‚ OpenAI Ğ¼ĞµÑ‚Ğ°Ñ„Ğ¾Ñ€Ğ°", "description": "Ğ¡Ğ²Ñ–Ñ‚Ğ½Ğ¸Ğ¹ Ğ½Ğ°Ğ¿Ñ–Ğ²Ğ¿Ñ€Ğ¾Ğ·Ğ¾Ñ€Ğ¸Ğ¹ Ğ·Ğ°Ñ…Ğ¸ÑĞ½Ğ¸Ğ¹ Ñ‰Ğ¸Ñ‚ Ğ· Ğ»Ğ¾Ğ³Ğ¾Ñ‚Ğ¸Ğ¿Ğ¾Ğ¼ OpenAI ÑˆĞ¸Ñ€ÑÑ” Ğ½Ğ°Ğ´ Ğ²ĞµĞ»Ğ¸Ñ‡ĞµĞ·Ğ½Ğ¾Ñ ÑĞµÑ€Ğ²ĞµÑ€Ğ½Ğ¾Ñ ĞºÑ–Ğ¼Ğ½Ğ°Ñ‚Ğ¾Ñ. Ğ‘Ñ–Ğ»Ğ¾-Ğ±Ğ»Ğ°ĞºĞ¸Ñ‚Ğ½Ğµ ÑĞ²Ñ–Ñ‚Ğ»Ğ¾ Ğ·Ğ°Ğ»Ğ¾Ğ¼Ğ»ÑÑ”Ñ‚ÑŒÑÑ Ñ‡ĞµÑ€ĞµĞ· Ñ‰Ğ¸Ñ‚, ÑÑ‚Ğ²Ğ¾Ñ€ÑÑÑ‡Ğ¸ Ğ³ĞµĞ¾Ğ¼ĞµÑ‚Ñ€Ğ¸Ñ‡Ğ½Ñ– Ğ²Ñ–Ğ·ĞµÑ€ÑƒĞ½ĞºĞ¸ Ğ½Ğ° Ñ‚ĞµĞ¼Ğ½Ğ¸Ñ… ÑĞµÑ€Ğ²ĞµÑ€Ğ½Ğ¸Ñ… ÑÑ‚Ñ–Ğ¹ĞºĞ°Ñ…. ĞšÑ–Ğ½ĞµĞ¼Ğ°Ñ‚Ğ¾Ğ³Ñ€Ğ°Ñ„Ñ–Ñ‡Ğ½Ğ¸Ğ¹ ÑˆĞ¸Ñ€Ğ¾ĞºĞ¸Ğ¹ ĞºÑƒÑ‚, Ñ…Ğ¾Ğ»Ğ¾Ğ´Ğ½Ğ° Ğ±Ğ»Ğ°ĞºĞ¸Ñ‚Ğ½Ğ° Ğ¿Ğ°Ğ»Ñ–Ñ‚Ñ€Ğ° Ğ· Ñ‚ĞµĞ¿Ğ»Ğ¸Ğ¼Ğ¸ Ğ±ÑƒÑ€ÑˆÑ‚Ğ¸Ğ½Ğ¾Ğ²Ğ¸Ğ¼Ğ¸ Ğ°ĞºÑ†ĞµĞ½Ñ‚Ğ°Ğ¼Ğ¸ Ğ²Ñ–Ğ´ Ñ–Ğ½Ğ´Ğ¸ĞºĞ°Ñ‚Ğ¾Ñ€Ñ–Ğ²."},
  {"label": "Ğ¦ĞµĞ½Ñ‚Ñ€ ĞºÑ–Ğ±ĞµÑ€Ğ·Ğ°Ñ…Ğ¸ÑÑ‚Ñƒ AI", "description": "Ğ¡ÑƒÑ‡Ğ°ÑĞ½Ğ¸Ğ¹ Ñ†ĞµĞ½Ñ‚Ñ€ ĞºÑ–Ğ±ĞµÑ€Ğ±ĞµĞ·Ğ¿ĞµĞºĞ¸ Ğ· Ğ²Ğ¸Ğ³Ğ½ÑƒÑ‚Ğ¸Ğ¼Ğ¸ Ğ´Ğ¸ÑĞ¿Ğ»ĞµÑĞ¼Ğ¸ Ñ‰Ğ¾ Ğ¿Ğ¾ĞºĞ°Ğ·ÑƒÑÑ‚ÑŒ ĞºĞ°Ñ€Ñ‚Ğ¸ Ğ·Ğ°Ğ³Ñ€Ğ¾Ğ· Ğ² Ñ€ĞµĞ°Ğ»ÑŒĞ½Ğ¾Ğ¼Ñƒ Ñ‡Ğ°ÑÑ– Ñ‚Ğ° Ğ²Ñ–Ğ·ÑƒĞ°Ğ»Ñ–Ğ·Ğ°Ñ†Ñ–Ñ— Ğ½ĞµĞ¹Ñ€Ğ¾Ğ¼ĞµÑ€ĞµĞ¶Ñ– OpenAI. Ğ”Ñ€Ğ°Ğ¼Ğ°Ñ‚Ğ¸Ñ‡Ğ½Ğµ Ğ¿Ñ€Ğ¸Ğ³Ğ»ÑƒÑˆĞµĞ½Ğµ Ğ¾ÑĞ²Ñ–Ñ‚Ğ»ĞµĞ½Ğ½Ñ Ğ· ĞµĞºÑ€Ğ°Ğ½Ğ°Ğ¼Ğ¸ Ñ‰Ğ¾ Ğ²Ñ–Ğ´ĞºĞ¸Ğ´Ğ°ÑÑ‚ÑŒ Ğ±Ğ»Ğ°ĞºĞ¸Ñ‚Ğ½Ğµ ÑÑĞ¹Ğ²Ğ¾ Ğ½Ğ° Ğ¿Ğ¾Ğ»Ñ–Ñ€Ğ¾Ğ²Ğ°Ğ½Ñ– Ğ¿Ğ¾Ğ²ĞµÑ€Ñ…Ğ½Ñ–. Ğ—Ğ¹Ğ¾Ğ¼ĞºĞ° Ñ‡ĞµÑ€ĞµĞ· Ğ¿Ğ»ĞµÑ‡Ğµ Ğ¾Ğ¿ĞµÑ€Ğ°Ñ‚Ğ¾Ñ€Ğ°, 4K editorial Ñ„Ğ¾Ñ‚Ğ¾Ğ³Ñ€Ğ°Ñ„Ñ–Ñ."},
  {"label": "ĞÑ€Ñ…Ñ–Ñ‚ĞµĞºÑ‚ÑƒÑ€Ğ° Ñ†Ğ¸Ñ„Ñ€Ğ¾Ğ²Ğ¾Ñ— Ñ„Ğ¾Ñ€Ñ‚ĞµÑ†Ñ–", "description": "Ğ¤Ğ¾Ñ‚Ğ¾Ñ€ĞµĞ°Ğ»Ñ–ÑÑ‚Ğ¸Ñ‡Ğ½Ğ° Ğ°Ñ€Ñ…Ñ–Ñ‚ĞµĞºÑ‚ÑƒÑ€Ğ½Ğ° Ğ²Ñ–Ğ·ÑƒĞ°Ğ»Ñ–Ğ·Ğ°Ñ†Ñ–Ñ Ğ¼Ğ°ÑĞ¸Ğ²Ğ½Ğ¾Ğ³Ğ¾ Ğ²Ñ…Ğ¾Ğ´Ñƒ Ğ´Ğ¾ Ğ´Ğ°Ñ‚Ğ°-Ñ†ĞµĞ½Ñ‚Ñ€Ñƒ Ñƒ Ğ²Ğ¸Ğ³Ğ»ÑĞ´Ñ– Ñ„ÑƒÑ‚ÑƒÑ€Ğ¸ÑÑ‚Ğ¸Ñ‡Ğ½Ğ¸Ñ… Ğ´Ğ²ĞµÑ€ĞµĞ¹ ÑĞµĞ¹Ñ„Ğ° Ğ· Ğ²Ğ¸Ğ³Ñ€Ğ°Ğ²Ñ–Ñ€ÑƒĞ²Ğ°Ğ½Ğ¸Ğ¼ Ğ½Ğ°Ğ¿Ğ¸ÑĞ¾Ğ¼ OpenAI Ğ½Ğ° Ğ¼Ğ°Ñ‚Ğ¾Ğ²Ñ–Ğ¹ ÑÑ‚Ğ°Ğ»Ñ–. Ğ Ğ°Ğ½ĞºĞ¾Ğ²Ğ¸Ğ¹ Ñ‚ÑƒĞ¼Ğ°Ğ½ Ğ¾Ñ‚Ğ¾Ñ‡ÑƒÑ” ĞºĞ¾Ğ½ÑÑ‚Ñ€ÑƒĞºÑ†Ñ–Ñ. ĞšÑ–Ğ½ĞµĞ¼Ğ°Ñ‚Ğ¾Ğ³Ñ€Ğ°Ñ„Ñ–Ñ‡Ğ½Ğ¸Ğ¹ Ñ€Ğ°ĞºÑƒÑ€Ñ Ğ· Ğ´Ñ€Ğ¾Ğ½Ğ°, Ğ¾ÑĞ²Ñ–Ñ‚Ğ»ĞµĞ½Ğ½Ñ Ğ·Ğ¾Ğ»Ğ¾Ñ‚Ğ¾Ñ— Ğ³Ğ¾Ğ´Ğ¸Ğ½Ğ¸."},
  {"label": "ĞœĞ°ĞºÑ€Ğ¾Ğ·Ğ¹Ğ¾Ğ¼ĞºĞ° Ğ½ĞµĞ¹Ñ€Ğ¾Ñ‡Ñ–Ğ¿Ğ°", "description": "Ğ•ĞºÑÑ‚Ñ€ĞµĞ¼Ğ°Ğ»ÑŒĞ½Ğ° Ğ¼Ğ°ĞºÑ€Ğ¾Ğ·Ğ¹Ğ¾Ğ¼ĞºĞ° ÑĞ¿ĞµÑ†Ñ–Ğ°Ğ»Ñ–Ğ·Ğ¾Ğ²Ğ°Ğ½Ğ¾Ğ³Ğ¾ AI Ñ‡Ñ–Ğ¿Ğ° Ğ±ĞµĞ·Ğ¿ĞµĞºĞ¸ Ğ· Ğ²Ğ¸Ğ´Ğ¸Ğ¼Ğ¸Ğ¼Ğ¸ Ğ½ĞµĞ¹Ñ€Ğ¾Ğ½Ğ½Ğ¸Ğ¼Ğ¸ ÑˆĞ»ÑÑ…Ğ°Ğ¼Ğ¸ Ñ‰Ğ¾ ÑĞ²Ñ–Ñ‚ÑÑ‚ÑŒÑÑ Ğ±Ğ»Ğ°ĞºĞ¸Ñ‚Ğ½Ğ¸Ğ¼. ĞœÑ–Ğ½Ñ–Ğ°Ñ‚ÑÑ€Ğ½Ğµ Ğ»Ğ¾Ğ³Ğ¾ OpenAI Ğ²Ğ¸Ğ³Ñ€Ğ°Ğ²Ñ–Ñ€ÑƒĞ²Ğ°Ğ½Ğµ Ğ»Ğ°Ğ·ĞµÑ€Ğ¾Ğ¼ Ğ½Ğ° ĞºÑ€ĞµĞ¼Ğ½Ñ–Ñ”Ğ²Ğ¾Ğ¼Ñƒ ĞºÑ€Ğ¸ÑÑ‚Ğ°Ğ»Ñ–. ĞœĞ°Ğ»Ğ° Ğ³Ğ»Ğ¸Ğ±Ğ¸Ğ½Ğ° Ñ€Ñ–Ğ·ĞºĞ¾ÑÑ‚Ñ–, Ñ‚ĞµĞ¼Ğ½Ğ¸Ğ¹ Ñ„Ğ¾Ğ½, ÑÑ‚ÑƒĞ´Ñ–Ğ¹Ğ½Ğµ Ğ¾ÑĞ²Ñ–Ñ‚Ğ»ĞµĞ½Ğ½Ñ."}
]

ĞŸĞ¾Ğ²ĞµÑ€Ñ‚Ğ°Ğ¹ Ğ¢Ğ†Ğ›Ğ¬ĞšĞ˜ JSON Ğ¼Ğ°ÑĞ¸Ğ²:
[
  {"label": "...", "description": "..."},
  {"label": "...", "description": "..."},
  {"label": "...", "description": "..."},
  {"label": "...", "description": "..."}
]`
}

/**
 * Run AI classifier to extract structured data from article
 * (Used only for STRUCTURED approach)
 */
async function runClassifier(supabase: any, title: string, content: string): Promise<ClassifierOutput | null> {
  try {
    // Get classifier prompt from database
    const { data: promptData } = await supabase
      .from('ai_prompts')
      .select('prompt_text')
      .eq('prompt_type', 'image_classifier')
      .eq('is_active', true)
      .order('updated_at', { ascending: false })
      .limit(1)
      .single()

    if (!promptData?.prompt_text) {
      console.error('âŒ Classifier prompt not found in database')
      return null
    }

    // Fill placeholders
    let classifierPrompt = promptData.prompt_text
    classifierPrompt = classifierPrompt.replace(/{title}/g, title)
    classifierPrompt = classifierPrompt.replace(/{content}/g, content.substring(0, 5000))

    // Call Azure OpenAI
    const azureUrl = `${AZURE_OPENAI_ENDPOINT}/openai/deployments/Jobbot-gpt-4.1-mini/chat/completions?api-version=2024-02-15-preview`

    const response = await fetch(azureUrl, {
      method: 'POST',
      headers: {
        'Content-Type': 'application/json',
        'api-key': AZURE_OPENAI_API_KEY!
      },
      body: JSON.stringify({
        messages: [
          {
            role: 'system',
            content: 'You are a precise data extractor. Always respond with valid JSON only, no markdown formatting, no explanations.'
          },
          { role: 'user', content: classifierPrompt }
        ],
        temperature: 0.3,
        max_tokens: 800
      })
    })

    if (!response.ok) {
      const errorText = await response.text()
      console.error('âŒ Azure OpenAI API error:', response.status, errorText)
      return null
    }

    const data = await response.json()
    let jsonString = data.choices[0]?.message?.content?.trim()

    if (!jsonString) {
      console.error('âŒ No content in AI response')
      return null
    }

    // Clean up JSON if wrapped in markdown code blocks
    jsonString = jsonString.replace(/```json\n?/g, '').replace(/```\n?/g, '').trim()

    try {
      const parsed = JSON.parse(jsonString) as ClassifierOutput

      // Validate required fields
      if (!parsed.company_name || !parsed.category || !parsed.visual_concept) {
        console.error('âŒ Missing required fields in classifier output')
        return null
      }

      // Normalize category
      if (!CATEGORY_TO_TEMPLATE[parsed.category]) {
        console.warn(`âš ï¸ Unknown category "${parsed.category}", defaulting to "general"`)
        parsed.category = 'general'
      }

      return parsed
    } catch (parseError) {
      console.error('âŒ Failed to parse classifier JSON:', parseError, jsonString)
      return null
    }

  } catch (error: any) {
    console.error('âŒ Error running classifier:', error)
    return null
  }
}

/**
 * Get template from database by prompt_type
 */
async function getTemplate(supabase: any, templateType: string): Promise<string | null> {
  try {
    const { data } = await supabase
      .from('ai_prompts')
      .select('prompt_text')
      .eq('prompt_type', templateType)
      .eq('is_active', true)
      .order('updated_at', { ascending: false })
      .limit(1)
      .single()

    return data?.prompt_text || null
  } catch {
    return null
  }
}

/**
 * Fill template with classifier data
 */
function fillTemplate(template: string, data: ClassifierOutput): string {
  let result = template

  // Get colors for category
  const colors = CATEGORY_COLORS[data.category] || CATEGORY_COLORS['general']

  // Basic replacements
  result = result.replace(/{company_name}/g, data.company_name || 'Brand')
  result = result.replace(/{company_domain}/g, data.company_domain || '')
  result = result.replace(/{product_type}/g, data.product_type || '')
  result = result.replace(/{visual_concept}/g, data.visual_concept || '')
  result = result.replace(/{color_scheme}/g, data.color_scheme || '')
  result = result.replace(/{style_hint}/g, data.style_hint || '')
  result = result.replace(/{color_primary}/g, colors.primary)
  result = result.replace(/{color_secondary}/g, colors.secondary)

  // Format visual elements as comma-separated list
  const visualElementsList = (data.visual_elements || []).join(', ')
  result = result.replace(/{visual_elements}/g, visualElementsList)

  // Format key features as bullet points for info blocks
  const keyFeaturesFormatted = (data.key_features || [])
    .map((f, i) => `â–¡ "${f.toUpperCase()}"`)
    .join('\n')
  result = result.replace(/{key_features_formatted}/g, keyFeaturesFormatted)

  // Generic CTA
  result = result.replace(/{cta_text}/g, 'Learn More')

  return result
}

/**
 * Default fallback template if database is unavailable
 */
function getDefaultTemplate(): string {
  return `Professional technology news illustration.

MAIN SUBJECT:
{visual_concept}

VISUAL ELEMENTS to include:
{visual_elements}

COMPOSITION:
- Central focus on the main visual concept
- Professional, editorial quality suitable for tech news
- Clean, modern aesthetic with balanced composition
- 1:1 aspect ratio (square)

COLOR PALETTE:
- Primary accent: {color_primary}
- Secondary accent: {color_secondary}
- Professional gradient backgrounds

STYLE GUIDE:
- Photorealistic 3D rendering with soft lighting
- Subtle depth of field effect
- Abstract geometric elements in background
- High-end product photography aesthetic
- NO text, logos, or written words in the image
- Focus purely on visual storytelling

QUALITY BOOST (MANDATORY):
- Ultra high resolution, 8K quality rendering
- Vibrant saturated colors with high contrast
- Sharp crisp details, absolutely no blur or artifacts
- Professional studio lighting with soft shadows
- Rich color depth and dynamic range
- Photorealistic textures and materials

MOOD: Professional, innovative, forward-thinking technology`
}
