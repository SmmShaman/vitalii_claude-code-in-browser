name: Real-time News Scraper

on:
  schedule:
    # Run every 10 minutes
    - cron: '*/10 * * * *'
  workflow_dispatch:

jobs:
  scrape:
    runs-on: ubuntu-latest

    steps:
      - name: Get active sources and pick one
        id: pick
        env:
          SUPABASE_ANON_KEY: ${{ secrets.NEXT_PUBLIC_SUPABASE_ANON_KEY }}
        run: |
          # Fetch sources
          SOURCES=$(curl -s "https://uchmopqiylywnemvjttl.supabase.co/rest/v1/news_sources?select=id,name&is_active=eq.true&source_type=eq.telegram" \
            -H "apikey: $SUPABASE_ANON_KEY")

          echo "Raw response: $SOURCES"

          COUNT=$(echo "$SOURCES" | jq 'length')
          echo "Source count: $COUNT"

          if [ "$COUNT" -eq "0" ] || [ -z "$COUNT" ]; then
            echo "No active sources found"
            echo "source_id=" >> $GITHUB_OUTPUT
            echo "source_name=none" >> $GITHUB_OUTPUT
            exit 0
          fi

          # Get current minute of the hour (0-59)
          MINUTE=$(date +%M)
          # Remove leading zero for arithmetic
          MINUTE=$((10#$MINUTE))

          # Round-robin: pick source based on minute
          INDEX=$((MINUTE / 10 % COUNT))

          SOURCE_ID=$(echo "$SOURCES" | jq -r ".[$INDEX].id")
          SOURCE_NAME=$(echo "$SOURCES" | jq -r ".[$INDEX].name")

          echo "Minute: $MINUTE, Index: $INDEX"
          echo "Selected: $SOURCE_NAME ($SOURCE_ID)"

          echo "source_id=$SOURCE_ID" >> $GITHUB_OUTPUT
          echo "source_name=$SOURCE_NAME" >> $GITHUB_OUTPUT

      - name: Scrape selected source
        if: steps.pick.outputs.source_id != ''
        env:
          SUPABASE_ANON_KEY: ${{ secrets.NEXT_PUBLIC_SUPABASE_ANON_KEY }}
          SOURCE_ID: ${{ steps.pick.outputs.source_id }}
          SOURCE_NAME: ${{ steps.pick.outputs.source_name }}
        run: |
          echo "ðŸ•·ï¸ Scraping: $SOURCE_NAME"

          RESULT=$(curl -s -X POST "https://uchmopqiylywnemvjttl.supabase.co/functions/v1/telegram-scraper" \
            -H "Authorization: Bearer $SUPABASE_ANON_KEY" \
            -H "Content-Type: application/json" \
            -d "{\"source_id\": \"$SOURCE_ID\"}" \
            --max-time 150)

          echo "Result: $RESULT"

          # Check if successful
          OK=$(echo "$RESULT" | jq -r '.ok // false')
          if [ "$OK" = "true" ]; then
            echo "âœ… Scraping completed successfully"
          else
            echo "âŒ Scraping failed"
            echo "$RESULT" | jq '.'
            exit 1
          fi

      - name: Summary
        if: always()
        run: |
          echo "## Scraper Run Summary" >> $GITHUB_STEP_SUMMARY
          echo "" >> $GITHUB_STEP_SUMMARY
          echo "- **Source:** ${{ steps.pick.outputs.source_name }}" >> $GITHUB_STEP_SUMMARY
          echo "- **Time:** $(date -u '+%Y-%m-%d %H:%M UTC')" >> $GITHUB_STEP_SUMMARY
