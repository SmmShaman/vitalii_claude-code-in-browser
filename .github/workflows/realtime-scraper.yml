name: Real-time News Scraper

on:
  schedule:
    # Run every 10 minutes
    - cron: '*/10 * * * *'
  workflow_dispatch:
    inputs:
      source_name:
        description: 'Specific source to scrape (leave empty for round-robin)'
        required: false
        default: ''

jobs:
  scrape:
    runs-on: ubuntu-latest

    steps:
      - name: Get active sources
        id: sources
        run: |
          SOURCES=$(curl -s "https://uchmopqiylywnemvjttl.supabase.co/rest/v1/news_sources?select=id,name&is_active=eq.true&source_type=eq.telegram" \
            -H "apikey: ${{ secrets.NEXT_PUBLIC_SUPABASE_ANON_KEY }}")
          echo "sources=$SOURCES" >> $GITHUB_OUTPUT
          echo "Found sources: $SOURCES"

      - name: Calculate which source to process
        id: pick
        run: |
          # Get current minute of the hour (0-59)
          MINUTE=$(date +%M)
          # Get sources as array
          SOURCES='${{ steps.sources.outputs.sources }}'
          COUNT=$(echo "$SOURCES" | jq 'length')

          if [ "$COUNT" -eq "0" ]; then
            echo "No active sources found"
            echo "source_id=" >> $GITHUB_OUTPUT
            exit 0
          fi

          # Round-robin: pick source based on minute
          # Every 10 min = 6 times per hour, we have 6 sources
          INDEX=$((MINUTE / 10 % COUNT))

          SOURCE_ID=$(echo "$SOURCES" | jq -r ".[$INDEX].id")
          SOURCE_NAME=$(echo "$SOURCES" | jq -r ".[$INDEX].name")

          echo "Minute: $MINUTE, Index: $INDEX, Source: $SOURCE_NAME ($SOURCE_ID)"
          echo "source_id=$SOURCE_ID" >> $GITHUB_OUTPUT
          echo "source_name=$SOURCE_NAME" >> $GITHUB_OUTPUT

      - name: Scrape selected source
        if: steps.pick.outputs.source_id != ''
        run: |
          echo "ðŸ•·ï¸ Scraping: ${{ steps.pick.outputs.source_name }}"

          RESULT=$(curl -s -X POST "https://uchmopqiylywnemvjttl.supabase.co/functions/v1/telegram-scraper" \
            -H "Authorization: Bearer ${{ secrets.NEXT_PUBLIC_SUPABASE_ANON_KEY }}" \
            -H "Content-Type: application/json" \
            -d '{"source_id": "${{ steps.pick.outputs.source_id }}"}' \
            --max-time 150)

          echo "Result: $RESULT"

          # Check if successful
          OK=$(echo "$RESULT" | jq -r '.ok // false')
          if [ "$OK" = "true" ]; then
            echo "âœ… Scraping completed successfully"
          else
            echo "âŒ Scraping failed"
            echo "$RESULT" | jq '.'
            exit 1
          fi

      - name: Summary
        if: always()
        run: |
          echo "## Scraper Run Summary" >> $GITHUB_STEP_SUMMARY
          echo "" >> $GITHUB_STEP_SUMMARY
          echo "- **Source:** ${{ steps.pick.outputs.source_name }}" >> $GITHUB_STEP_SUMMARY
          echo "- **Time:** $(date -u '+%Y-%m-%d %H:%M UTC')" >> $GITHUB_STEP_SUMMARY
